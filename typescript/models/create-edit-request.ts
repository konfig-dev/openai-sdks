/* tslint:disable */
/* eslint-disable */
/**
 * OpenAI API
 * APIs for sampling from and fine-tuning language models
 *
 * The version of the OpenAPI document: 1.2.0
 * 
 *
 * NOTE: This file is auto generated by Konfig (https://konfigthis.com).
 * https://konfigthis.com
 * Do not edit the class manually.
 */


/**
 * 
 * @export
 * @interface CreateEditRequest
 */
export interface CreateEditRequest {
    /**
     * ID of the model to use. You can use the `text-davinci-edit-001` or `code-davinci-edit-001` model with this endpoint.
     * @type {string}
     * @memberof CreateEditRequest
     */
    'model': string;
    /**
     * The input text to use as a starting point for the edit.
     * @type {string}
     * @memberof CreateEditRequest
     */
    'input'?: string | null;
    /**
     * The instruction that tells the model how to edit the prompt.
     * @type {string}
     * @memberof CreateEditRequest
     */
    'instruction': string;
    /**
     * How many edits to generate for the input and instruction.
     * @type {number}
     * @memberof CreateEditRequest
     */
    'n'?: number | null;
    /**
     * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.  We generally recommend altering this or `top_p` but not both. 
     * @type {number}
     * @memberof CreateEditRequest
     */
    'temperature'?: number | null;
    /**
     * An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.  We generally recommend altering this or `temperature` but not both. 
     * @type {number}
     * @memberof CreateEditRequest
     */
    'top_p'?: number | null;
}

